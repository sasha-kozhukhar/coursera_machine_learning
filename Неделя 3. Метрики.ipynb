{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "34\n",
      "59\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv('classification.csv')\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "par = [x[1] for x in data.iterrows()]\n",
    "for i in par:\n",
    "    if i[0] == 0 and i[1] == 0:\n",
    "        TN+=1\n",
    "    elif i[0] == 1 and i[1] == 1:\n",
    "        TP+=1\n",
    "    elif i[0] == 0 and i[1] == 1:\n",
    "        FP+=1\n",
    "    elif i[0] == 1 and i[1] == 0:\n",
    "        FN+=1\n",
    "# TP, FP, FN, TN\n",
    "print(TP)\n",
    "print(FP)\n",
    "print(FN)\n",
    "print(TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n",
      "0.56\n",
      "0.42\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(round(accuracy_score(data['true'],data['pred']), 2))\n",
    "print(round(precision_score(data['true'],data['pred']), 2))\n",
    "print(round(recall_score(data['true'],data['pred']), 2))\n",
    "print(round(f1_score(data['true'],data['pred']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>score_logreg</th>\n",
       "      <th>score_svm</th>\n",
       "      <th>score_knn</th>\n",
       "      <th>score_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683832</td>\n",
       "      <td>0.145976</td>\n",
       "      <td>0.787063</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801966</td>\n",
       "      <td>0.239511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.382315</td>\n",
       "      <td>-0.245701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.506797</td>\n",
       "      <td>-0.137058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.488781</td>\n",
       "      <td>-0.154148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true  score_logreg  score_svm  score_knn  score_tree\n",
       "0     0      0.683832   0.145976   0.787063    0.500000\n",
       "1     1      0.801966   0.239511   1.000000    0.833333\n",
       "2     0      0.382315  -0.245701   0.000000    0.000000\n",
       "3     1      0.506797  -0.137058   0.000000    0.105263\n",
       "4     1      0.488781  -0.154148   0.000000    0.105263"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atad = pandas.read_csv('scores.csv')\n",
    "atad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_logreg  0.72\n",
      "score_svm  0.71\n",
      "score_knn  0.64\n",
      "score_tree  0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('score_logreg ', round(roc_auc_score(atad['true'],atad['score_logreg']), 2))\n",
    "print('score_svm ', round(roc_auc_score(atad['true'],atad['score_svm']), 2))\n",
    "print('score_knn ', round(roc_auc_score(atad['true'],atad['score_knn']), 2))\n",
    "print('score_tree ', round(roc_auc_score(atad['true'],atad['score_tree']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "86\n",
      "111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision = precision_recall_curve(atad['true'], atad['score_logreg'])[0]\n",
    "recall = precision_recall_curve(atad['true'], atad['score_logreg'])[1]\n",
    "thresholds = precision_recall_curve(atad['true'], atad['score_logreg'])[2]\n",
    "n = 0\n",
    "for i in recall:\n",
    "    if i >= 0.7:\n",
    "        n+=1\n",
    "print(len(recall))\n",
    "print(n)\n",
    "#197\n",
    "print(197-86)\n",
    "#111\n",
    "np.amax(precision[111:197])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "89\n",
      "110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision = precision_recall_curve(atad['true'], atad['score_svm'])[0]\n",
    "recall = precision_recall_curve(atad['true'], atad['score_svm'])[1]\n",
    "thresholds = precision_recall_curve(atad['true'], atad['score_svm'])[2]\n",
    "n = 0\n",
    "for i in recall:\n",
    "    if i >= 0.7:\n",
    "        n+=1\n",
    "print(len(recall))\n",
    "print(n)\n",
    "#199\n",
    "print(199-89)\n",
    "#110\n",
    "np.amax(precision[110:199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "41\n",
      "63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34693877551020408"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision = precision_recall_curve(atad['true'], atad['score_knn'])[0]\n",
    "recall = precision_recall_curve(atad['true'], atad['score_knn'])[1]\n",
    "thresholds = precision_recall_curve(atad['true'], atad['score_knn'])[2]\n",
    "n = 0\n",
    "for i in recall:\n",
    "    if i >= 0.7:\n",
    "        n+=1\n",
    "print(len(recall))\n",
    "print(n)\n",
    "#104\n",
    "print(104-41)\n",
    "#14\n",
    "np.amax(precision[63:104])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "6\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision = precision_recall_curve(atad['true'], atad['score_tree'])[0]\n",
    "recall = precision_recall_curve(atad['true'], atad['score_tree'])[1]\n",
    "thresholds = precision_recall_curve(atad['true'], atad['score_tree'])[2]\n",
    "n = 0\n",
    "for i in recall:\n",
    "    if i >= 0.7:\n",
    "        n+=1\n",
    "print(len(recall))\n",
    "print(n)\n",
    "#12\n",
    "print(12-6)\n",
    "#6\n",
    "np.amax(precision[6:12])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
